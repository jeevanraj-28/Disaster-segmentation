"""
Diagnostic Script for Visualization Notebook Preparation
=========================================================
This script checks all necessary files, data, and configurations
needed for creating the visualization notebook.
"""

import os
import json
import numpy as np
import torch
from pathlib import Path

print("="*70)
print("ğŸ” DISASTER SEGMENTATION PROJECT - DIAGNOSTIC CHECK")
print("="*70)

# Base paths
base_path = Path(r"D:\Projects\Image_Segmentation_for_Disaster_Resilience\Disaster-segmentation")

# ============================================================
# 1. CHECK MODEL CHECKPOINT
# ============================================================
print("\n" + "="*70)
print("1ï¸âƒ£  CHECKING MODEL CHECKPOINT")
print("="*70)

model_path = base_path / "models" / "checkpoints" / "unet_resnet34_best.pth"
if model_path.exists():
    print(f"âœ… Model found: {model_path}")
    try:
        checkpoint = torch.load(model_path, map_location='cpu')
        print(f"   ğŸ“¦ Checkpoint keys: {list(checkpoint.keys())}")
        if 'epoch' in checkpoint:
            print(f"   ğŸ“Š Trained for {checkpoint['epoch']} epochs")
        if 'best_miou' in checkpoint:
            print(f"   ğŸ¯ Best mIoU: {checkpoint['best_miou']:.4f}")
        if 'model_state_dict' in checkpoint:
            print(f"   âœ… Model state dict found")
    except Exception as e:
        print(f"   âš ï¸  Error loading checkpoint: {e}")
else:
    print(f"âŒ Model NOT found at: {model_path}")

# ============================================================
# 2. CHECK SAVED EVALUATION RESULTS
# ============================================================
print("\n" + "="*70)
print("2ï¸âƒ£  CHECKING EVALUATION RESULTS")
print("="*70)

results_json = base_path / "results" / "evaluation" / "test_evaluation_results.json"
if results_json.exists():
    print(f"âœ… Results JSON found: {results_json}")
    try:
        with open(results_json, 'r') as f:
            results = json.load(f)
        print(f"   ğŸ“Š Available metrics: {list(results.keys())}")
        if 'mean_iou' in results:
            print(f"   ğŸ¯ Mean IoU: {results['mean_iou']:.4f}")
        if 'pixel_accuracy' in results:
            print(f"   ğŸ¯ Pixel Accuracy: {results['pixel_accuracy']:.4f}")
        if 'per_class_iou' in results:
            print(f"   ğŸ“ˆ Per-class IoU available:")
            if isinstance(results['per_class_iou'], dict):
                for class_name, iou in results['per_class_iou'].items():
                    print(f"      - {class_name}: {iou:.4f}")
            else:
                print(f"      - {len(results['per_class_iou'])} classes")
    except Exception as e:
        print(f"   âš ï¸  Error loading results: {e}")
        results = None
else:
    print(f"âŒ Results JSON NOT found at: {results_json}")
    results = None

confusion_matrix_path = base_path / "results" / "evaluation" / "confusion_matrix.npy"
if confusion_matrix_path.exists():
    print(f"\nâœ… Confusion matrix found: {confusion_matrix_path}")
    try:
        cm = np.load(confusion_matrix_path)
        print(f"   ğŸ“Š Shape: {cm.shape} (classes x classes)")
        print(f"   ğŸ“Š Total predictions: {cm.sum():.0f}")
    except Exception as e:
        print(f"   âš ï¸  Error loading confusion matrix: {e}")
else:
    print(f"\nâŒ Confusion matrix NOT found at: {confusion_matrix_path}")

sample_ious_path = base_path / "results" / "metrics" / "test_sample_ious.csv"
if sample_ious_path.exists():
    print(f"\nâœ… Sample IoUs CSV found: {sample_ious_path}")
    try:
        import pandas as pd
        df = pd.read_csv(sample_ious_path)
        print(f"   ğŸ“Š Number of samples: {len(df)}")
        print(f"   ğŸ“Š Columns: {list(df.columns)}")
        if 'mean_iou' in df.columns:
            print(f"   ğŸ“Š Mean IoU range: {df['mean_iou'].min():.4f} - {df['mean_iou'].max():.4f}")
    except Exception as e:
        print(f"   âš ï¸  Error loading CSV: {e}")
else:
    print(f"\nâŒ Sample IoUs CSV NOT found at: {sample_ious_path}")

# ============================================================
# 3. CHECK TEST DATASET
# ============================================================
print("\n" + "="*70)
print("3ï¸âƒ£  CHECKING TEST DATASET")
print("="*70)

test_path = base_path / "data" / "raw" / "FloodNet" / "test"
if test_path.exists():
    print(f"âœ… Test directory found: {test_path}")

    # List all subdirectories
    subdirs = [d for d in test_path.iterdir() if d.is_dir()]
    print(f"   ğŸ“ Subdirectories: {[d.name for d in subdirs]}")

    # Check for images
    image_dirs = ['images', 'image', 'Image', 'test-image']
    image_path = None
    for img_dir in image_dirs:
        potential_path = test_path / img_dir
        if potential_path.exists():
            image_path = potential_path
            break

    if image_path is None:
        image_path = test_path

    image_files = list(image_path.glob("*.jpg")) + list(image_path.glob("*.png"))
    print(f"\n   ğŸ–¼ï¸  Image path: {image_path}")
    print(f"   ğŸ–¼ï¸  Test images found: {len(image_files)}")
    if image_files:
        print(f"   ğŸ“ First 3 examples:")
        for img in image_files[:3]:
            print(f"      - {img.name}")

    # Check for masks
    mask_dirs = ['masks', 'mask', 'Mask', 'test-label']
    mask_path = None
    for msk_dir in mask_dirs:
        potential_path = test_path / msk_dir
        if potential_path.exists():
            mask_path = potential_path
            break

    if mask_path is None:
        mask_path = test_path

    mask_files = list(mask_path.glob("*.png")) + list(mask_path.glob("*.jpg"))
    print(f"\n   ğŸ­ Mask path: {mask_path}")
    print(f"   ğŸ­ Test masks found: {len(mask_files)}")
    if mask_files:
        print(f"   ğŸ“ First 3 examples:")
        for msk in mask_files[:3]:
            print(f"      - {msk.name}")
else:
    print(f"âŒ Test directory NOT found at: {test_path}")

# ============================================================
# 4. CHECK GPU AVAILABILITY
# ============================================================
print("\n" + "="*70)
print("4ï¸âƒ£  CHECKING GPU")
print("="*70)

if torch.cuda.is_available():
    print(f"âœ… CUDA available: {torch.cuda.get_device_name(0)}")
    print(f"   ğŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
    print(f"   ğŸ”¢ CUDA Version: {torch.version.cuda}")
else:
    print(f"âš ï¸  CUDA not available, will use CPU")

# ============================================================
# 5. CHECK FOR SAVED PREDICTIONS
# ============================================================
print("\n" + "="*70)
print("5ï¸âƒ£  CHECKING FOR SAVED PREDICTIONS")
print("="*70)

prediction_paths = [
    base_path / "results" / "predictions",
    base_path / "predictions",
    base_path / "outputs" / "predictions",
]

predictions_found = False
for pred_path in prediction_paths:
    if pred_path.exists():
        pred_files = list(pred_path.glob("*.npy")) + list(pred_path.glob("*.pt")) + list(pred_path.glob("*.png"))
        if pred_files:
            print(f"âœ… Predictions found at: {pred_path}")
            print(f"   ğŸ“Š Number of files: {len(pred_files)}")
            predictions_found = True
            break

if not predictions_found:
    print(f"âš ï¸  No saved predictions found.")
    print(f"   ğŸ’¡ We'll need to generate predictions from the model during visualization")

# ============================================================
# 6. CHECK PROJECT STRUCTURE
# ============================================================
print("\n" + "="*70)
print("6ï¸âƒ£  CHECKING PROJECT STRUCTURE")
print("="*70)

important_dirs = {
    "Source code": base_path / "src",
    "Notebooks": base_path / "notebooks",
    "Models": base_path / "models",
    "Data": base_path / "data",
    "Results": base_path / "results",
}

for name, path in important_dirs.items():
    if path.exists():
        print(f"âœ… {name}: {path}")
    else:
        print(f"âŒ {name}: NOT FOUND at {path}")

# Check for visualization output directory
vis_output = base_path / "results" / "visualizations"
if not vis_output.exists():
    print(f"\nğŸ’¡ Creating visualization output directory: {vis_output}")
    vis_output.mkdir(parents=True, exist_ok=True)
    print(f"   âœ… Created: {vis_output}")
else:
    print(f"\nâœ… Visualization output directory exists: {vis_output}")

# ============================================================
# 7. SUMMARY AND RECOMMENDATIONS
# ============================================================
print("\n" + "="*70)
print("ğŸ“‹ SUMMARY & RECOMMENDATIONS")
print("="*70)

checks = {
    "âœ… Model checkpoint": model_path.exists(),
    "âœ… Evaluation results JSON": results_json.exists(),
    "âœ… Confusion matrix": confusion_matrix_path.exists(),
    "âœ… Sample IoUs CSV": sample_ious_path.exists(),
    "âœ… Test dataset": test_path.exists(),
    "âœ… GPU available": torch.cuda.is_available(),
}

print("\nğŸ“Š STATUS:")
for item, status in checks.items():
    symbol = "âœ…" if status else "âŒ"
    print(f"   {symbol} {item.split(maxsplit=1)[1]}")

ready_count = sum(checks.values())
total_count = len(checks)
print(f"\nğŸ¯ Ready: {ready_count}/{total_count} components")

print("\n" + "="*70)
print("ğŸš€ NEXT STEPS")
print("="*70)

if ready_count >= 4:
    print("âœ… Sufficient resources available for visualization!")
    print("\nğŸ“ We can create:")
    print("   1. âœ… Comparison grids (Image | GT | Prediction)")
    print("   2. âœ… Per-class IoU bar charts")
    print("   3. âœ… Confusion matrix heatmap")
    print("   4. âœ… Overlay visualizations")
    print("   5. âœ… Error analysis plots")
    print("\nğŸ’¡ Next: Share this output to generate 05_visualization.ipynb")
else:
    print("âš ï¸  Some critical resources missing.")
    print("   Review the output above and ensure:")
    print("   - Model checkpoint exists")
    print("   - Evaluation results are saved")
    print("   - Test dataset is accessible")

print("\n" + "="*70)
print("âœ¨ DIAGNOSTIC CHECK COMPLETE")
print("="*70)
